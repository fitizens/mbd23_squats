{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7df0c1-1487-4d16-b032-7839a723a94a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T21:23:47.245223100Z",
     "start_time": "2023-12-26T21:23:47.198918900Z"
    }
   },
   "outputs": [],
   "source": [
    "from fitizens_libraries.load_data import load_labeled_data\n",
    "from scipy.signal import find_peaks\n",
    "from custom_libraries.load_data_for_label import load_data_for_label\n",
    "from custom_libraries.merge_data import merge_data\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import numpy as np\n",
    "from custom_libraries.find_peaks import find_peaks_cust\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2220a9-b1ab-4c6b-9bdf-83febc7cdf25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T21:22:02.477059500Z",
     "start_time": "2023-12-26T21:22:02.398205700Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"LABELED\"\n",
    "os.makedirs(folder_path, exist_ok=True) #Referenciamos la carpeta LABELED en la que están las carpetas zip con los json\n",
    "#Ahora voy a iterar en esa carpeta LABELED para obtener la ruta de los archivos, que es el LABELED/NOMBRE y eso lo guardo en una lista\n",
    "file_names = []\n",
    "for name in os.listdir(folder_path):\n",
    "    file_path = f\"{folder_path}/{name}\"\n",
    "    file_names.append(file_path)\n",
    "#Ahora tengo que especificar mis features \n",
    "signals = [\"accX\", \"accY\", \"accZ\", \"gyroX\", \"gyroY\", \"gyroZ\", \"magnX\", \"magnY\", \"magnZ\", \"linAccX\", \"linAccY\", \"linAccZ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d076077-d148-4da7-8f54-a0ef1b9bc080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T21:22:06.295647400Z",
     "start_time": "2023-12-26T21:22:05.976850900Z"
    }
   },
   "outputs": [],
   "source": [
    "datos = load_data_for_label(filelist=file_names[0:2],\n",
    "                       signals= signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556bcadb-7da7-4ea5-9441-8801eade29cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T21:22:07.884836500Z",
     "start_time": "2023-12-26T21:22:07.790245300Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8def00-0527-44d7-9bab-f2613100affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce2c53-f144-48bb-a5d4-e948e8885e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a27b6c-464d-49f4-b5d7-105a620cadca",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b6fac-851b-421e-a527-2930bb58eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(datos,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b34e245-e23c-48bc-9581-da2fb094ccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8191e32-e39e-42b3-adac-41ffb0354f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_1000 = df.head(4000)\n",
    "fig = px.line(prim_1000, x=prim_1000.index, y='linAccZ', title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342687b3-f3e2-4703-8c01-322340b35b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Crear la figura de la serie de tiempo\n",
    "fig = go.Figure()\n",
    "\n",
    "# Añadir la línea de la serie de tiempo\n",
    "fig.add_trace(go.Scatter(x=prim_1000.index, y=prim_1000['linAccZ'], mode='lines', name='linAccZ'))\n",
    "\n",
    "# Filtrar los índices de los picos\n",
    "peaks_indices = prim_1000.index[prim_1000['peaks'].notna()]\n",
    "\n",
    "# Añadir marcadores para los picos en la gráfica\n",
    "fig.add_trace(go.Scatter(x=peaks_indices, y=prim_1000.loc[peaks_indices, 'linAccZ'],\n",
    "                         mode='markers', marker=dict(color='red'), name='peaks'))\n",
    "\n",
    "# Establecer el título de la gráfica\n",
    "fig.update_layout(title='Time serie of exercise linAccZ')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7721c59-378e-4061-aae0-5e1c0cba26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952cc246-67d6-43eb-a738-5576cb268b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ ESTA ES PARA EL SQUAT EN EL SEGUNDO BONCHE DE DATOS #################\n",
    "############## NO LO EJECUTES #####################\n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "modelo = joblib.load('modeloXGB.pkl')\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "            'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "            'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "            'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "            'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "nuevo_df_list = []  # Lista para almacenar las filas\n",
    "\n",
    "for idx, fila in df.iloc[51:].iterrows():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    nuevo_df_list.append(fila.copy())  # Añadir la fila a la lista\n",
    "    if pd.notna(fila['peaks']):\n",
    "        nuevo_df = pd.DataFrame(nuevo_df_list)  # Convertir la lista en DataFrame\n",
    "        \n",
    "        promedio = nuevo_df.mean().add_prefix('mean_')\n",
    "        std = nuevo_df.std().add_prefix('std_')\n",
    "        median = nuevo_df.median().add_prefix('median_')\n",
    "        nuevo_df_estad = pd.DataFrame().append(pd.concat([promedio, std, median]), ignore_index=True)\n",
    "        \n",
    "        X1 = nuevo_df_estad[features].copy()\n",
    "        y_pred = modelo.predict(X1)\n",
    "        \n",
    "        inicio_ventana = nuevo_df.index[0] \n",
    "        fin_ventana = nuevo_df.index[-1]\n",
    "        \n",
    "        X1['start'] = inicio_ventana\n",
    "        X1['end'] = fin_ventana\n",
    "        X1['prediccion'] = y_pred[0]\n",
    "    \n",
    "        nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8fa92-7a1c-4193-9308-fd26130ce948",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_df_predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4adc71-3932-41bd-83a3-d3f9572c0372",
   "metadata": {},
   "source": [
    "## Fraccionar los datos segun los picos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2cc05b-948f-4cb4-aa6c-f05848fb2d16",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ea413-3155-4583-a358-fcfe6dd8dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "nuevo_df_list = []  # Lista para almacenar las filas\n",
    "modelo = joblib.load('modeloXGB.pkl')\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "            'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "            'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "            'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "            'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "for idx, fila in df.iterrows():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    nuevo_df_list.append(fila.copy())  # Añadir la fila a la lista\n",
    "    \n",
    "    if pd.notna(fila['peaks']):\n",
    "        nuevo_df = pd.DataFrame(nuevo_df_list)  # Convertir la lista en DataFrame\n",
    "\n",
    "        promedio = nuevo_df.mean().add_prefix('mean_')\n",
    "        std = nuevo_df.std().add_prefix('std_')\n",
    "        median = nuevo_df.median().add_prefix('median_')\n",
    "        nuevo_df_estad = pd.DataFrame().append(pd.concat([promedio, std, median]), ignore_index=True)\n",
    "\n",
    "        X1 = nuevo_df_estad[features].copy()\n",
    "        y_pred = modelo.predict(X1)\n",
    "\n",
    "\n",
    "        X1['start'] = nuevo_df.index[0]\n",
    "        X1['end'] = nuevo_df.index[-1]\n",
    "        X1['prediccion'] = y_pred[0]\n",
    "\n",
    "        nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)\n",
    "\n",
    "        # Limpiar la lista para la próxima ventana\n",
    "        nuevo_df_list = [fila.copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bca0c2-4d09-4c7c-a393-f42ce585ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_detection = nuevo_df_predicciones[nuevo_df_predicciones.prediccion == 1][['start', 'end', 'prediccion']]\n",
    "squats_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e7938-6b53-41cf-9876-c6b9e3ac6c7a",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84239713-6256-4789-9f32-eaa7316e456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "nuevo_df_list = []  # Lista para almacenar las filas\n",
    "modelo2 = joblib.load('modeloNB.pkl')\n",
    "scaler =  joblib.load('scaler3.pkl')\n",
    "\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "            'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "            'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "            'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "            'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "for idx, fila in df.iterrows():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    nuevo_df_list.append(fila.copy())  # Añadir la fila a la lista\n",
    "    \n",
    "    if pd.notna(fila['peaks']):\n",
    "        nuevo_df = pd.DataFrame(nuevo_df_list)  # Convertir la lista en DataFrame\n",
    "\n",
    "        promedio = nuevo_df.mean().add_prefix('mean_')\n",
    "        std = nuevo_df.std().add_prefix('std_')\n",
    "        median = nuevo_df.median().add_prefix('median_')\n",
    "        nuevo_df_estad = pd.DataFrame().append(pd.concat([promedio, std, median]), ignore_index=True)\n",
    "\n",
    "        X1 = nuevo_df_estad[features].copy()\n",
    "        X1_full = scaler.transform(X1)\n",
    "        y_pred = modelo2.predict(X1_full)\n",
    "\n",
    "        X1['start'] = nuevo_df.index[0]\n",
    "        X1['end'] = nuevo_df.index[-1]\n",
    "        X1['prediccion'] = y_pred[0]\n",
    "        \n",
    "        nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)\n",
    "\n",
    "        # Limpiar la lista para la próxima ventana\n",
    "        nuevo_df_list = [fila.copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f0d03-f0a4-4dd4-98de-9665a1f98442",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_detection = nuevo_df_predicciones[nuevo_df_predicciones.prediccion == 1][['start', 'end', 'prediccion']]\n",
    "squats_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f953bd0-eaf4-4a77-b318-758441b7cdc0",
   "metadata": {},
   "source": [
    "## Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7381c7-e9a9-4791-beb1-2cd2b2878186",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "nuevo_df_list = []  # Lista para almacenar las filas\n",
    "modelo3 = joblib.load('modeloLR.pkl')\n",
    "scaler =  joblib.load('scaler3.pkl')\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "            'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "            'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "            'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "            'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "for idx, fila in df.iterrows():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    nuevo_df_list.append(fila.copy())  # Añadir la fila a la lista\n",
    "    \n",
    "    if pd.notna(fila['peaks']):\n",
    "        nuevo_df = pd.DataFrame(nuevo_df_list)  # Convertir la lista en DataFrame\n",
    "\n",
    "        promedio = nuevo_df.mean().add_prefix('mean_')\n",
    "        std = nuevo_df.std().add_prefix('std_')\n",
    "        median = nuevo_df.median().add_prefix('median_')\n",
    "        nuevo_df_estad = pd.DataFrame().append(pd.concat([promedio, std, median]), ignore_index=True)\n",
    "\n",
    "        X1 = nuevo_df_estad[features].copy()\n",
    "        X1_full = scaler.transform(X1)\n",
    "        y_pred = modelo3.predict(X1_full)\n",
    "        \n",
    "        X1['start'] = nuevo_df.index[0]\n",
    "        X1['end'] = nuevo_df.index[-1]\n",
    "        X1['prediccion'] = y_pred[0]\n",
    "\n",
    "        nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)\n",
    "\n",
    "        # Limpiar la lista para la próxima ventana\n",
    "        nuevo_df_list = [fila.copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4360fb2-1c97-4ef4-9c5e-fff286613471",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_detection = nuevo_df_predicciones[nuevo_df_predicciones.prediccion == 1][['start', 'end', 'prediccion']]\n",
    "squats_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e59749-0234-4a7a-8349-4a6e04a023e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Hacia abajo NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f7e6b8-2f66-4b51-8cf1-e0a5e6c8359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_squat_time_range(df_workout):\n",
    "    # Identify start and end times\n",
    "    squats_detection = pd.concat([df_workout[ df_workout.first_sample == True ], df_workout[ df_workout.last_sample == True ]]).sort_index()\n",
    "    \n",
    "    start_times = squats_detection[squats_detection['first_sample']].index\n",
    "    end_times = squats_detection[squats_detection['last_sample']].index\n",
    "    \n",
    "    paired_times = list(zip(start_times, end_times))\n",
    "    \n",
    "    # Create new DataFrame\n",
    "    return pd.DataFrame(paired_times, columns=['start', 'end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef29453c-d062-46b6-b0e4-55155fedc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_squat_time_range(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ad85f-506f-43a3-ac44-54baab219698",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fed973-bc38-453c-8463-fe12d45ff16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(df.exercise,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63aa37c-c113-4ee2-bf86-64018106d0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=df['exercise'], label = \"squat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe0f43-2d63-4de0-b5c4-f02a550a7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81937cc2-fb07-4839-9fef-78fdeec117d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df['exercise'] == 'NO_EXERCISE','exercising_periods'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806eb92-b850-46ed-9b21-cb233e0833ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "prim_1000 = df.head(2000)\n",
    "fig = px.line(prim_1000, x=prim_1000.index, y='linAccZ', color=\"exercise\",title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404953c-c01c-47f9-a732-be6d6f1a33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_100 = df.head(167)\n",
    "fig = px.line(prim_100, x=prim_100.index, y='linAccZ', color=\"exercise\",title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ed859-c761-4aed-bc91-7b17eba37757",
   "metadata": {},
   "outputs": [],
   "source": [
    "siguientes_170 = df.iloc[168:336]\n",
    "\n",
    "fig = px.line(siguientes_170, x=siguientes_170.index, y='linAccZ', color=\"exercise\", title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb415b-2291-4e82-8fa4-6ec157e2543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "siguientes_170 = df.iloc[336:510]\n",
    "\n",
    "fig = px.line(siguientes_170, x=siguientes_170.index, y='linAccZ', color=\"exercise\", title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02707d9-a5ca-4fbe-ac0f-3ae8a1c5c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = joblib.load('modeloXGB.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2e55c-ffb7-48ff-b240-9090ae494471",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =  joblib.load('scaler3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba68dd-5349-45d2-98c4-db3c0a65ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de2d25-ba86-421e-9ed7-22a55aa13a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['peaks', 'first_sample','last_sample', 'first_sample_closest_peak', \n",
    "             'last_sample_closest_peak','exercise','accY', 'exercising_periods'], axis=1)\n",
    "y = df['exercise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548352a-c937-4e4a-b4d3-b775e2f33341",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6f371-4614-4b90-9a14-b4925bce4fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a293ead-8491-4ad2-afbc-a35b6b291450",
   "metadata": {},
   "source": [
    "## Modelo XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b317a-33e2-4899-8222-3a9c099190aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tamano_ventana = 170 \n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "       'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "       'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "       'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "       'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "for i in range(0, len(X) - tamano_ventana + 1, tamano_ventana):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # Seleccionar la ventana de datos\n",
    "    ventana = X.iloc[i:i + tamano_ventana]\n",
    "    #print(ventana)\n",
    "\n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    nuevo_df = pd.DataFrame().append(pd.concat([promedio_serie.add_prefix('mean_'), std_serie.add_prefix('std_'), median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    \n",
    "    X1= nuevo_df[features].copy()\n",
    "    y_pred = modelo.predict(X1)\n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4edc02-0d9f-4976-9008-88897c26cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_detection = nuevo_df_predicciones[nuevo_df_predicciones.prediccion == 1][['start', 'end', 'prediccion']]\n",
    "squats_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b5b38-70de-4e2f-b28d-cb32c8d6c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea05366-1840-4b2c-a2e3-5df740e992aa",
   "metadata": {},
   "source": [
    "## Modelo de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c50f94-5c6f-41ba-a453-88fb4577b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tamano_ventana = 170\n",
    "nuevo_df = pd.DataFrame\n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "       'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "       'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "       'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "       'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "modelo2 = joblib.load('modeloNB.pkl')\n",
    "\n",
    "for i in range(0, len(X) - tamano_ventana + 1, tamano_ventana):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # Seleccionar la ventana de datos\n",
    "    ventana = X.iloc[i:i + tamano_ventana]\n",
    "    #print(ventana)\n",
    "\n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    nuevo_df = pd.DataFrame().append(pd.concat([promedio_serie.add_prefix('mean_'), std_serie.add_prefix('std_'), median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    " \n",
    "    X1= nuevo_df[features].copy()\n",
    "    X1_full = scaler.transform(X1)\n",
    "    y_pred = modelo2.predict(X1_full)\n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68734c0f-c1e7-4a98-8a78-6f3fcf3bf64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(nuevo_df_predicciones.prediccion,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d703086-2ad1-4d9a-a336-a82dc71bcaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_detection = nuevo_df_predicciones[nuevo_df_predicciones.prediccion == 1][['start', 'end', 'prediccion']]\n",
    "squats_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66efa5f-68ea-4735-9577-4be7de0327e7",
   "metadata": {},
   "source": [
    "## Modelo Regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98bfef-5e98-42c3-8007-727a97652a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tamano_ventana = 170 \n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "       'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "       'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "       'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "       'median_gyroX_mod', 'median_linAccX_mod']\n",
    "# Scale Data\n",
    "modelo3 = joblib.load('modeloLR.pkl')\n",
    "\n",
    "for i in range(0, len(X) - tamano_ventana + 1, tamano_ventana):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # Seleccionar la ventana de datos\n",
    "    ventana = X.iloc[i:i + tamano_ventana]\n",
    "    #print(ventana)\n",
    "\n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    nuevo_df = pd.DataFrame().append(pd.concat([promedio_serie.add_prefix('mean_'), std_serie.add_prefix('std_'), median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "    #nuevo_df = nuevo_df.append(pd.concat([promedio_serie.add_prefix('mean_'), std_serie.add_prefix('std_'), median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    \n",
    "    X1= nuevo_df[features].copy()\n",
    "    X1_full = scaler.transform(X1)\n",
    "    y_pred = modelo3.predict(X1_full)\n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf3965-cab9-4cd4-ac87-74fe1d056910",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(nuevo_df_predicciones.prediccion,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc530c38-0360-4156-844b-096b2e46c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_detection = nuevo_df_predicciones[nuevo_df_predicciones.prediccion == 1][['start', 'end', 'prediccion']]\n",
    "squats_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaea971-454e-4e0f-84d2-f24f86a6daf8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Ventana por tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f5b5b-91be-42c6-a74d-c2a39b84de52",
   "metadata": {},
   "source": [
    "Teniendo en cuenta las graficas, ahora se porbará hacer ventanas con tiempos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf564a-f8ac-40aa-98c6-1d3c9c42e38e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfe2ae0-4f4e-4432-9b36-72b616fdd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "X.index = pd.to_datetime(X.index)\n",
    "tamano_ventana_segundos = 1.85  # Ahora la ventana es de 1.85 segundos\n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "            'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "            'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "            'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "            'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "# Ajusta la ventana inicial para incluir el primer dato\n",
    "ventana_inicio = X.index[0]\n",
    "ventana_fin = ventana_inicio + timedelta(seconds=tamano_ventana_segundos)\n",
    "\n",
    "while ventana_fin <= X.index[-1]:\n",
    "    # Seleccionar la ventana de datos basada en el tiempo\n",
    "    ventana = X.loc[(X.index >= ventana_inicio) & (X.index <= ventana_fin)]\n",
    "    \n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    \n",
    "    nuevo_df = pd.DataFrame().append(pd.concat([promedio_serie.add_prefix('mean_'), \n",
    "                                           std_serie.add_prefix('std_'), \n",
    "                                           median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    X1 = nuevo_df[features].copy()\n",
    "    y_pred = modelo.predict(X1)\n",
    "    \n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    \n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)\n",
    "\n",
    "    # Mover la ventana al siguiente intervalo de tiempo\n",
    "    ventana_inicio = ventana_fin\n",
    "    ventana_fin = ventana_inicio + timedelta(seconds=tamano_ventana_segundos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464477e-d03b-43df-81c1-0463952111fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_detection = nuevo_df_predicciones[nuevo_df_predicciones.prediccion == 1][['start', 'end', 'prediccion']]\n",
    "squats_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead32801-1b97-45fc-933f-0c4af365ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d405b4-b81c-4b5e-b3bf-d3eb41ec805c",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12deb846-5db5-44c9-8a6c-8f3465fec150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "X.index = pd.to_datetime(X.index)\n",
    "modelo2 = joblib.load('modeloNB.pkl')\n",
    "\n",
    "tamano_ventana_segundos = 1.85  # Ahora la ventana es de 1.85 segundos\n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "            'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "            'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "            'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "            'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "# Ajusta la ventana inicial para incluir el primer dato\n",
    "ventana_inicio = X.index[0]\n",
    "ventana_fin = ventana_inicio + timedelta(seconds=tamano_ventana_segundos)\n",
    "\n",
    "while ventana_fin <= X.index[-1]:\n",
    "    # Seleccionar la ventana de datos basada en el tiempo\n",
    "    ventana = X.loc[(X.index >= ventana_inicio) & (X.index <= ventana_fin)]\n",
    "    \n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    \n",
    "    nuevo_df = pd.DataFrame().append(pd.concat([promedio_serie.add_prefix('mean_'), \n",
    "                                           std_serie.add_prefix('std_'), \n",
    "                                           median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    X1 = nuevo_df[features].copy()\n",
    "    X1_full = scaler.transform(X1)\n",
    "    y_pred = modelo2.predict(X1)\n",
    "    \n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    \n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)\n",
    "\n",
    "    # Mover la ventana al siguiente intervalo de tiempo\n",
    "    ventana_inicio = ventana_fin\n",
    "    ventana_fin = ventana_inicio + timedelta(seconds=tamano_ventana_segundos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfdecf0-9d85-4f58-b8c8-ff404a568056",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_df_predicciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e95c4-31fe-42f5-926c-ef12d13168cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(nuevo_df_predicciones.prediccion,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110b53e-4c7d-46e1-a8d8-caf4f6d52475",
   "metadata": {},
   "source": [
    "## Regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a3aed-24b5-468a-b563-32c748f35812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "X.index = pd.to_datetime(X.index)\n",
    "modelo3 = joblib.load('modeloLR.pkl')\n",
    "\n",
    "tamano_ventana_segundos = 1.85  # Ahora la ventana es de 1.85 segundos\n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "            'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "            'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "            'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "            'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "# Ajusta la ventana inicial para incluir el primer dato\n",
    "ventana_inicio = X.index[0]\n",
    "ventana_fin = ventana_inicio + timedelta(seconds=tamano_ventana_segundos)\n",
    "\n",
    "while ventana_fin <= X.index[-1]:\n",
    "    # Seleccionar la ventana de datos basada en el tiempo\n",
    "    ventana = X.loc[(X.index >= ventana_inicio) & (X.index <= ventana_fin)]\n",
    "    \n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    \n",
    "    nuevo_df = pd.DataFrame().append(pd.concat([promedio_serie.add_prefix('mean_'), \n",
    "                                           std_serie.add_prefix('std_'), \n",
    "                                           median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    X1 = nuevo_df[features].copy()\n",
    "    X1_full = scaler.transform(X1)\n",
    "    y_pred = modelo3.predict(X1)\n",
    "    \n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    \n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)\n",
    "\n",
    "    # Mover la ventana al siguiente intervalo de tiempo\n",
    "    ventana_inicio = ventana_fin\n",
    "    ventana_fin = ventana_inicio + timedelta(seconds=tamano_ventana_segundos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227774e8-7b2e-4d78-a908-e4a54aa9e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_df_predicciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bacbe8f-82d9-446e-a947-5afcd8145c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(nuevo_df_predicciones.prediccion,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe2e90-4b9e-45df-a0b2-29b1c52413af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
