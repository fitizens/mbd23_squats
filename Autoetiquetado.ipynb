{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7df0c1-1487-4d16-b032-7839a723a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitizens_libraries.load_data import load_labeled_data\n",
    "from scipy.signal import find_peaks\n",
    "from Autolabeler import workout\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2220a9-b1ab-4c6b-9bdf-83febc7cdf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"LABELED\"\n",
    "os.makedirs(folder_path, exist_ok=True) #Referenciamos la carpeta LABELED en la que están las carpetas zip con los json\n",
    "#Ahora voy a iterar en esa carpeta LABELED para obtener la ruta de los archivos, que es el LABELED/NOMBRE y eso lo guardo en una lista\n",
    "file_names = []\n",
    "for name in os.listdir(folder_path):\n",
    "    file_path = f\"{folder_path}/{name}\"\n",
    "    file_names.append(file_path)\n",
    "#Ahora tengo que especificar mis features \n",
    "signals = [\"accX\", \"accY\", \"accZ\", \"gyroX\", \"gyroY\", \"gyroZ\", \"magnX\", \"magnY\", \"magnZ\", \"linAccX\", \"linAccY\", \"linAccZ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d076077-d148-4da7-8f54-a0ef1b9bc080",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = workout(filelist=file_names,\n",
    "                       signals= signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a27b6c-464d-49f4-b5d7-105a620cadca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ad85f-506f-43a3-ac44-54baab219698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fed973-bc38-453c-8463-fe12d45ff16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(df.exercise,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63aa37c-c113-4ee2-bf86-64018106d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=df['exercise'], label = \"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe0f43-2d63-4de0-b5c4-f02a550a7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81937cc2-fb07-4839-9fef-78fdeec117d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df['exercise'] == 'NO_EXERCISE','exercising_periods'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806eb92-b850-46ed-9b21-cb233e0833ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "prim_1000 = df.head(2000)\n",
    "fig = px.line(prim_1000, x=prim_1000.index, y='linAccZ', color=\"exercise\",title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404953c-c01c-47f9-a732-be6d6f1a33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_100 = df.head(167)\n",
    "fig = px.line(prim_100, x=prim_100.index, y='linAccZ', color=\"exercise\",title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ed859-c761-4aed-bc91-7b17eba37757",
   "metadata": {},
   "outputs": [],
   "source": [
    "siguientes_170 = df.iloc[168:336]\n",
    "\n",
    "fig = px.line(siguientes_170, x=siguientes_170.index, y='linAccZ', color=\"exercise\", title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb415b-2291-4e82-8fa4-6ec157e2543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "siguientes_170 = df.iloc[336:510]\n",
    "\n",
    "fig = px.line(siguientes_170, x=siguientes_170.index, y='linAccZ', color=\"exercise\", title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02707d9-a5ca-4fbe-ac0f-3ae8a1c5c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = joblib.load('modeloXGB.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de2d25-ba86-421e-9ed7-22a55aa13a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['peaks', 'first_sample','last_sample', 'first_sample_closest_peak', \n",
    "             'last_sample_closest_peak','exercise','accY', 'exercising_periods'], axis=1)\n",
    "y = df['exercise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548352a-c937-4e4a-b4d3-b775e2f33341",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6f371-4614-4b90-9a14-b4925bce4fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a293ead-8491-4ad2-afbc-a35b6b291450",
   "metadata": {},
   "source": [
    "## Modelo XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff5ed20-a519-4682-be47-880f1459d1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tamano_ventana = 170 \n",
    "nuevo_df = pd.DataFrame()\n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "       'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "       'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "       'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "       'median_gyroX_mod', 'median_linAccX_mod']\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for i in range(0, len(X) - tamano_ventana + 1, tamano_ventana):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # Seleccionar la ventana de datos\n",
    "    ventana = X.iloc[i:i + tamano_ventana]\n",
    "    #print(ventana)\n",
    "\n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    nuevo_df = nuevo_df.append(pd.concat([promedio_serie.add_prefix('mean_'), std_serie.add_prefix('std_'), median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    \n",
    "    X1= nuevo_df[features].copy()\n",
    "    y_pred = modelo.predict(X1)\n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b5b38-70de-4e2f-b28d-cb32c8d6c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_df_predicciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdcd05b-a06a-437d-8cee-8e5a9055e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(nuevo_df_predicciones.prediccion,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea05366-1840-4b2c-a2e3-5df740e992aa",
   "metadata": {},
   "source": [
    "## Modelo de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c50f94-5c6f-41ba-a453-88fb4577b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tamano_ventana = 170 \n",
    "nuevo_df = pd.DataFrame()\n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "       'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "       'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "       'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "       'median_gyroX_mod', 'median_linAccX_mod']\n",
    "# Scale Data\n",
    "scaler =  joblib.load('scaler3.pkl')\n",
    "modelo2 = joblib.load('modeloNB.pkl')\n",
    "\n",
    "for i in range(0, len(X) - tamano_ventana + 1, tamano_ventana):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # Seleccionar la ventana de datos\n",
    "    ventana = X.iloc[i:i + tamano_ventana]\n",
    "    #print(ventana)\n",
    "\n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    nuevo_df = nuevo_df.append(pd.concat([promedio_serie.add_prefix('mean_'), std_serie.add_prefix('std_'), median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    \n",
    "    X1= nuevo_df[features].copy()\n",
    "    X1_full = scaler.transform(X1)\n",
    "    y_pred = modelo2.predict(X1_full)\n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68734c0f-c1e7-4a98-8a78-6f3fcf3bf64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(nuevo_df_predicciones.prediccion,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d703086-2ad1-4d9a-a336-a82dc71bcaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_df_predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66efa5f-68ea-4735-9577-4be7de0327e7",
   "metadata": {},
   "source": [
    "## Modelo Regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98bfef-5e98-42c3-8007-727a97652a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tamano_ventana = 170 \n",
    "nuevo_df = pd.DataFrame()\n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "       'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "       'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "       'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "       'median_gyroX_mod', 'median_linAccX_mod']\n",
    "# Scale Data\n",
    "scaler = StandardScaler()\n",
    "modelo3 = joblib.load('modeloLR.pkl')\n",
    "\n",
    "for i in range(0, len(X) - tamano_ventana + 1, tamano_ventana):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # Seleccionar la ventana de datos\n",
    "    ventana = X.iloc[i:i + tamano_ventana]\n",
    "    #print(ventana)\n",
    "\n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    nuevo_df = nuevo_df.append(pd.concat([promedio_serie.add_prefix('mean_'), std_serie.add_prefix('std_'), median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    \n",
    "    X1= nuevo_df[features].copy()\n",
    "    X1_full = scaler.transform(X1)\n",
    "    y_pred = modelo3.predict(X1_full)\n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf3965-cab9-4cd4-ac87-74fe1d056910",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(nuevo_df_predicciones.prediccion,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc530c38-0360-4156-844b-096b2e46c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_df_predicciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e8d95-3bdb-4acb-8415-5e9a3a62a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(std_serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58956338-ca4f-4841-a506-ddfdc81addb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Predicciones para la ventana {i+1}-{i+tamano_ventana}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f501a-c6e0-44f0-baf6-2b711ac00954",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735c584-40a2-4cf5-8e34-d49f7e78bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar la búsqueda del overlap óptimo\n",
    "tamanos_ventana = 170  # Puedes ajustar este rango según tus necesidades\n",
    "\n",
    "# Incluir el tamaño de ventana deseado en la lista\n",
    "for tamano_ventana in tamanos_ventana:\n",
    "    for overlap in porcentajes_overlap:\n",
    "        # Calcular el tamaño de paso (stride) basado en el porcentaje de overlap\n",
    "        paso = int(tamano_ventana * (1 - overlap / 100))\n",
    "\n",
    "        # Inicializar la validación cruzada en series temporales\n",
    "        tscv = TimeSeriesSplit(n_splits=(len(df) - tamano_ventana) // paso)\n",
    "        window = X_test.iloc[i:i+tamano_ventana]\n",
    "        # Almacenar las puntuaciones de precisión para cada configuración\n",
    "        puntuaciones = []\n",
    "\n",
    "        for train_index, test_index in tscv.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            window_features = []\n",
    "\n",
    "            # Hacer predicciones usando el modelo cargado\n",
    "            y_pred = modelo.predict(X_test)\n",
    "\n",
    "            # Calcular la precisión\n",
    "            precision = accuracy_score(y_test, y_pred)\n",
    "            puntuaciones.append(precision)\n",
    "\n",
    "        # Almacenar la precisión promedio para esta configuración\n",
    "        clave_configuracion = (tamano_ventana, overlap)\n",
    "        resultados[clave_configuracion] = sum(puntuaciones) / len(puntuaciones)\n",
    "\n",
    "# Imprimir los resultados\n",
    "for configuracion, precision in resultados.items():\n",
    "    print(f\"Configuración: Tamaño de ventana {configuracion[0]} datos, Overlap {configuracion[1]}%, Precisión promedio: {precision}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
