{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7df0c1-1487-4d16-b032-7839a723a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitizens_libraries.load_data import load_labeled_data\n",
    "from scipy.signal import find_peaks\n",
    "from Autolabeler import workout\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2220a9-b1ab-4c6b-9bdf-83febc7cdf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"LABELED\"\n",
    "os.makedirs(folder_path, exist_ok=True) #Referenciamos la carpeta LABELED en la que están las carpetas zip con los json\n",
    "#Ahora voy a iterar en esa carpeta LABELED para obtener la ruta de los archivos, que es el LABELED/NOMBRE y eso lo guardo en una lista\n",
    "file_names = []\n",
    "for name in os.listdir(folder_path):\n",
    "    file_path = f\"{folder_path}/{name}\"\n",
    "    file_names.append(file_path)\n",
    "#Ahora tengo que especificar mis features \n",
    "signals = [\"accX\", \"accY\", \"accZ\", \"gyroX\", \"gyroY\", \"gyroZ\", \"magnX\", \"magnY\", \"magnZ\", \"linAccX\", \"linAccY\", \"linAccZ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d076077-d148-4da7-8f54-a0ef1b9bc080",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = workout(filelist=file_names[0:1],\n",
    "                       signals= signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f7e6b8-2f66-4b51-8cf1-e0a5e6c8359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_squat_time_range(df_workout):\n",
    "    # Identify start and end times\n",
    "    squats_detection = pd.concat([df_workout[ df_workout.first_sample == True ], df_workout[ df_workout.last_sample == True ]]).sort_index()\n",
    "    \n",
    "    start_times = squats_detection[squats_detection['first_sample']].index\n",
    "    end_times = squats_detection[squats_detection['last_sample']].index\n",
    "    \n",
    "    # Assuming each start is followed by an end, pair them\n",
    "    paired_times = list(zip(start_times, end_times))\n",
    "    \n",
    "    # Create new DataFrame\n",
    "    return pd.DataFrame(paired_times, columns=['start', 'end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef29453c-d062-46b6-b0e4-55155fedc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_squat_time_range(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a27b6c-464d-49f4-b5d7-105a620cadca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ad85f-506f-43a3-ac44-54baab219698",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fed973-bc38-453c-8463-fe12d45ff16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(df.exercise,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63aa37c-c113-4ee2-bf86-64018106d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=df['exercise'], label = \"squat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe0f43-2d63-4de0-b5c4-f02a550a7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81937cc2-fb07-4839-9fef-78fdeec117d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df['exercise'] == 'NO_EXERCISE','exercising_periods'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806eb92-b850-46ed-9b21-cb233e0833ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "prim_1000 = df.head(2000)\n",
    "fig = px.line(prim_1000, x=prim_1000.index, y='linAccZ', color=\"exercise\",title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404953c-c01c-47f9-a732-be6d6f1a33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_100 = df.head(167)\n",
    "fig = px.line(prim_100, x=prim_100.index, y='linAccZ', color=\"exercise\",title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ed859-c761-4aed-bc91-7b17eba37757",
   "metadata": {},
   "outputs": [],
   "source": [
    "siguientes_170 = df.iloc[168:336]\n",
    "\n",
    "fig = px.line(siguientes_170, x=siguientes_170.index, y='linAccZ', color=\"exercise\", title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb415b-2291-4e82-8fa4-6ec157e2543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "siguientes_170 = df.iloc[336:510]\n",
    "\n",
    "fig = px.line(siguientes_170, x=siguientes_170.index, y='linAccZ', color=\"exercise\", title='Time serie of exercise linAccZ')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02707d9-a5ca-4fbe-ac0f-3ae8a1c5c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = joblib.load('modeloXGB.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2e55c-ffb7-48ff-b240-9090ae494471",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =  joblib.load('scaler3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba68dd-5349-45d2-98c4-db3c0a65ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de2d25-ba86-421e-9ed7-22a55aa13a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['peaks', 'first_sample','last_sample', 'first_sample_closest_peak', \n",
    "             'last_sample_closest_peak','exercise','accY', 'exercising_periods'], axis=1)\n",
    "y = df['exercise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548352a-c937-4e4a-b4d3-b775e2f33341",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6f371-4614-4b90-9a14-b4925bce4fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a293ead-8491-4ad2-afbc-a35b6b291450",
   "metadata": {},
   "source": [
    "## Modelo XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b317a-33e2-4899-8222-3a9c099190aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tamano_ventana = 170 \n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "       'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "       'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "       'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "       'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "for i in range(0, len(X) - tamano_ventana + 1, tamano_ventana):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # Seleccionar la ventana de datos\n",
    "    ventana = X.iloc[i:i + tamano_ventana]\n",
    "    #print(ventana)\n",
    "\n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    nuevo_df = pd.DataFrame().append(pd.concat([promedio_serie.add_prefix('mean_'), std_serie.add_prefix('std_'), median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    \n",
    "    X1= nuevo_df[features].copy()\n",
    "    y_pred = modelo.predict(X1)\n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4edc02-0d9f-4976-9008-88897c26cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_detection = nuevo_df_predicciones[nuevo_df_predicciones.prediccion == 1][['start', 'end', 'prediccion']]\n",
    "squats_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b5b38-70de-4e2f-b28d-cb32c8d6c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea05366-1840-4b2c-a2e3-5df740e992aa",
   "metadata": {},
   "source": [
    "## Modelo de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c50f94-5c6f-41ba-a453-88fb4577b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tamano_ventana = 170\n",
    "nuevo_df = pd.DataFrame\n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "       'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "       'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "       'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "       'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "modelo2 = joblib.load('modeloNB.pkl')\n",
    "\n",
    "for i in range(0, len(X) - tamano_ventana + 1, tamano_ventana):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # Seleccionar la ventana de datos\n",
    "    ventana = X.iloc[i:i + tamano_ventana]\n",
    "    #print(ventana)\n",
    "\n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    nuevo_df = pd.DataFrame().append(pd.concat([promedio_serie.add_prefix('mean_'), std_serie.add_prefix('std_'), median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    " \n",
    "    X1= nuevo_df[features].copy()\n",
    "    X1_full = scaler.transform(X1)\n",
    "    y_pred = modelo2.predict(X1_full)\n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68734c0f-c1e7-4a98-8a78-6f3fcf3bf64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(nuevo_df_predicciones.prediccion,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d703086-2ad1-4d9a-a336-a82dc71bcaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_detection = nuevo_df_predicciones[nuevo_df_predicciones.prediccion == 1][['start', 'end', 'prediccion']]\n",
    "squats_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66efa5f-68ea-4735-9577-4be7de0327e7",
   "metadata": {},
   "source": [
    "## Modelo Regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98bfef-5e98-42c3-8007-727a97652a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tamano_ventana = 170 \n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "       'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "       'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "       'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "       'median_gyroX_mod', 'median_linAccX_mod']\n",
    "# Scale Data\n",
    "modelo3 = joblib.load('modeloLR.pkl')\n",
    "\n",
    "for i in range(0, len(X) - tamano_ventana + 1, tamano_ventana):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # Seleccionar la ventana de datos\n",
    "    ventana = X.iloc[i:i + tamano_ventana]\n",
    "    #print(ventana)\n",
    "\n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    nuevo_df = pd.DataFrame().append(pd.concat([promedio_serie.add_prefix('mean_'), std_serie.add_prefix('std_'), median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "    #nuevo_df = nuevo_df.append(pd.concat([promedio_serie.add_prefix('mean_'), std_serie.add_prefix('std_'), median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    \n",
    "    X1= nuevo_df[features].copy()\n",
    "    X1_full = scaler.transform(X1)\n",
    "    y_pred = modelo3.predict(X1_full)\n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf3965-cab9-4cd4-ac87-74fe1d056910",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(nuevo_df_predicciones.prediccion,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc530c38-0360-4156-844b-096b2e46c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_detection = nuevo_df_predicciones[nuevo_df_predicciones.prediccion == 1][['start', 'end', 'prediccion']]\n",
    "squats_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaea971-454e-4e0f-84d2-f24f86a6daf8",
   "metadata": {},
   "source": [
    "# Ventana por tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f5b5b-91be-42c6-a74d-c2a39b84de52",
   "metadata": {},
   "source": [
    "Teniendo en cuenta las graficas, ahora se porbará hacer ventanas con tiempos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf564a-f8ac-40aa-98c6-1d3c9c42e38e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfe2ae0-4f4e-4432-9b36-72b616fdd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "X.index = pd.to_datetime(X.index)\n",
    "tamano_ventana_segundos = 1.85  # Ahora la ventana es de 1.85 segundos\n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "            'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "            'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "            'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "            'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "# Ajusta la ventana inicial para incluir el primer dato\n",
    "ventana_inicio = X.index[0]\n",
    "ventana_fin = ventana_inicio + timedelta(seconds=tamano_ventana_segundos)\n",
    "\n",
    "while ventana_fin <= X.index[-1]:\n",
    "    # Seleccionar la ventana de datos basada en el tiempo\n",
    "    ventana = X.loc[(X.index >= ventana_inicio) & (X.index <= ventana_fin)]\n",
    "    \n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    \n",
    "    nuevo_df = pd.DataFrame().append(pd.concat([promedio_serie.add_prefix('mean_'), \n",
    "                                           std_serie.add_prefix('std_'), \n",
    "                                           median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    X1 = nuevo_df[features].copy()\n",
    "    y_pred = modelo.predict(X1)\n",
    "    \n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    \n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)\n",
    "\n",
    "    # Mover la ventana al siguiente intervalo de tiempo\n",
    "    ventana_inicio = ventana_fin\n",
    "    ventana_fin = ventana_inicio + timedelta(seconds=tamano_ventana_segundos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464477e-d03b-43df-81c1-0463952111fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_detection = nuevo_df_predicciones[nuevo_df_predicciones.prediccion == 0][['start', 'end', 'prediccion']]\n",
    "squats_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead32801-1b97-45fc-933f-0c4af365ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d405b4-b81c-4b5e-b3bf-d3eb41ec805c",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12deb846-5db5-44c9-8a6c-8f3465fec150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "X.index = pd.to_datetime(X.index)\n",
    "modelo2 = joblib.load('modeloNB.pkl')\n",
    "\n",
    "tamano_ventana_segundos = 1.85  # Ahora la ventana es de 1.85 segundos\n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "            'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "            'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "            'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "            'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "# Ajusta la ventana inicial para incluir el primer dato\n",
    "ventana_inicio = X.index[0]\n",
    "ventana_fin = ventana_inicio + timedelta(seconds=tamano_ventana_segundos)\n",
    "\n",
    "while ventana_fin <= X.index[-1]:\n",
    "    # Seleccionar la ventana de datos basada en el tiempo\n",
    "    ventana = X.loc[(X.index >= ventana_inicio) & (X.index <= ventana_fin)]\n",
    "    \n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    \n",
    "    nuevo_df = pd.DataFrame().append(pd.concat([promedio_serie.add_prefix('mean_'), \n",
    "                                           std_serie.add_prefix('std_'), \n",
    "                                           median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    X1 = nuevo_df[features].copy()\n",
    "    X1_full = scaler.transform(X1)\n",
    "    y_pred = modelo2.predict(X1)\n",
    "    \n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    \n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)\n",
    "\n",
    "    # Mover la ventana al siguiente intervalo de tiempo\n",
    "    ventana_inicio = ventana_fin\n",
    "    ventana_fin = ventana_inicio + timedelta(seconds=tamano_ventana_segundos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfdecf0-9d85-4f58-b8c8-ff404a568056",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_df_predicciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e95c4-31fe-42f5-926c-ef12d13168cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(nuevo_df_predicciones.prediccion,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110b53e-4c7d-46e1-a8d8-caf4f6d52475",
   "metadata": {},
   "source": [
    "## Regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a3aed-24b5-468a-b563-32c748f35812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "X.index = pd.to_datetime(X.index)\n",
    "modelo3 = joblib.load('modeloLR.pkl')\n",
    "\n",
    "tamano_ventana_segundos = 1.85  # Ahora la ventana es de 1.85 segundos\n",
    "nuevo_df_predicciones = pd.DataFrame()\n",
    "features = ['mean_accX', 'mean_accZ', 'mean_linAccZ', 'mean_accZ_mod',\n",
    "            'mean_gyroX_mod', 'mean_linAccX_mod', 'std_accZ', 'std_gyroX', 'std_gyroZ',\n",
    "            'std_magnX', 'std_linAccX', 'std_accZ_mod', 'std_linAccX_mod',\n",
    "            'median_accX', 'median_accZ', 'median_linAccZ', 'median_accZ_mod',\n",
    "            'median_gyroX_mod', 'median_linAccX_mod']\n",
    "\n",
    "# Ajusta la ventana inicial para incluir el primer dato\n",
    "ventana_inicio = X.index[0]\n",
    "ventana_fin = ventana_inicio + timedelta(seconds=tamano_ventana_segundos)\n",
    "\n",
    "while ventana_fin <= X.index[-1]:\n",
    "    # Seleccionar la ventana de datos basada en el tiempo\n",
    "    ventana = X.loc[(X.index >= ventana_inicio) & (X.index <= ventana_fin)]\n",
    "    \n",
    "    # Calcular estadísticas (promedio, desviación estándar, mediana) para cada columna de la ventana\n",
    "    promedio_serie = ventana.mean()\n",
    "    std_serie = ventana.std()\n",
    "    median_serie = ventana.median()\n",
    "    \n",
    "    nuevo_df = pd.DataFrame().append(pd.concat([promedio_serie.add_prefix('mean_'), \n",
    "                                           std_serie.add_prefix('std_'), \n",
    "                                           median_serie.add_prefix('median_')]), ignore_index=True)\n",
    "\n",
    "    X1 = nuevo_df[features].copy()\n",
    "    X1_full = scaler.transform(X1)\n",
    "    y_pred = modelo3.predict(X1)\n",
    "    \n",
    "    X1['start'] = ventana.index[0]\n",
    "    X1['end'] = ventana.index[-1]\n",
    "    X1['prediccion'] = y_pred[0]\n",
    "    \n",
    "    nuevo_df_predicciones = pd.concat([nuevo_df_predicciones, X1], ignore_index=True)\n",
    "\n",
    "    # Mover la ventana al siguiente intervalo de tiempo\n",
    "    ventana_inicio = ventana_fin\n",
    "    ventana_fin = ventana_inicio + timedelta(seconds=tamano_ventana_segundos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227774e8-7b2e-4d78-a908-e4a54aa9e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_df_predicciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bacbe8f-82d9-446e-a947-5afcd8145c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(nuevo_df_predicciones.prediccion,return_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
